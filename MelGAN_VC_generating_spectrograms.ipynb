{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MelGAN_VC_generating_spectrograms.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wojciechsadlik/MelGAN-VC-ThesisExperiments/blob/master/MelGAN_VC_generating_spectrograms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V00rptcdKSbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c65244-0108-4512-e843-f04753b8303d"
      },
      "source": [
        "#We'll be using TF 2.1 and torchaudio\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "!pip install soundfile                    #to save wav files\n",
        "!pip install --no-deps torchaudio==0.5.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
            "Collecting torchaudio==0.5.0\n",
            "  Downloading torchaudio-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 23.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: torchaudio\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "Successfully installed torchaudio-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAmiyxtl2J5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54597253-65ca-4ea4-a2d4-536498eaab25"
      },
      "source": [
        "#Connecting Drive to save model checkpoints during training and to use custom data, uncomment if needed\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEvqwT96l_Yq"
      },
      "source": [
        "#Imports\n",
        "\n",
        "from __future__ import print_function, division\n",
        "from glob import glob\n",
        "import scipy\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Concatenate, Conv2D, Conv2DTranspose, GlobalAveragePooling2D, UpSampling2D, LeakyReLU, ReLU, Add, Multiply, Lambda, Dot, BatchNormalization, Activation, ZeroPadding2D, Cropping2D, Cropping1D\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import TruncatedNormal, he_normal\n",
        "import tensorflow.keras.backend as K\n",
        "import datetime\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "import imageio\n",
        "import librosa\n",
        "import librosa.display\n",
        "from librosa.feature import melspectrogram\n",
        "import os\n",
        "import time\n",
        "import IPython\n",
        "import shutil"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbaM4WKrvO7r"
      },
      "source": [
        "#Hyperparameters\n",
        "\n",
        "hop=192               #hop size (window size = 6*hop)\n",
        "sr=16000              #sampling rate\n",
        "min_level_db=-100     #reference values to normalize data\n",
        "ref_level_db=20\n",
        "\n",
        "shape=24              #length of time axis of split specrograms to feed to generator            \n",
        "vec_len=128           #length of vector generated by siamese vector\n",
        "bs = 16               #batch size\n",
        "delta = 2.            #constant for siamese loss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9pIPj9hnyJ0"
      },
      "source": [
        "#There seems to be a problem with Tensorflow STFT, so we'll be using pytorch to handle offline mel-spectrogram generation and waveform reconstruction\n",
        "#For waveform reconstruction, a gradient-based method is used:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "import math\n",
        "import heapq\n",
        "from torchaudio.transforms import MelScale, Spectrogram\n",
        "\n",
        "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "specobj = Spectrogram(n_fft=6*hop, win_length=6*hop, hop_length=hop, pad=0, power=2, normalized=True)\n",
        "specfunc = specobj.forward\n",
        "melobj = MelScale(n_mels=hop, sample_rate=sr, f_min=0.)\n",
        "melfunc = melobj.forward\n",
        "\n",
        "def melspecfunc(waveform):\n",
        "  specgram = specfunc(waveform)\n",
        "  mel_specgram = melfunc(specgram)\n",
        "  return mel_specgram\n",
        "\n",
        "def normalize(S):\n",
        "  return np.clip((((S - min_level_db) / -min_level_db)*2.)-1., -1, 1)\n",
        "\n",
        "def melprep(wv,hop=192):\n",
        "  S = np.array(torch.squeeze(melspecfunc(torch.Tensor(wv).view(1,-1))).detach().cpu())\n",
        "  S = librosa.power_to_db(S)-ref_level_db\n",
        "  return normalize(S)\n",
        "\n",
        "def stftprep(wv,hop=192):\n",
        "  S = np.array(torch.squeeze(specfunc(torch.Tensor(wv).view(1,-1))).detach().cpu())\n",
        "  S = librosa.power_to_db(S)-ref_level_db\n",
        "  return normalize(S)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNRYjsCDqDjF"
      },
      "source": [
        "#Helper functions\n",
        "\n",
        "#Generate spectrograms from waveform array\n",
        "def to_melspec(data):\n",
        "  specs=np.empty(data.shape[0], dtype=object)\n",
        "  for i in range(data.shape[0]):\n",
        "    x = data[i]\n",
        "    S = melprep(x)\n",
        "    S = np.array(S, dtype=np.float32)\n",
        "    specs[i]=np.expand_dims(S, -1)\n",
        "  print(specs.shape)\n",
        "  return specs\n",
        "\n",
        "def to_stftspec(data):\n",
        "  specs=np.empty(data.shape[0], dtype=object)\n",
        "  for i in range(data.shape[0]):\n",
        "    x = data[i]\n",
        "    S = stftprep(x)\n",
        "    S = np.array(S, dtype=np.float32)\n",
        "    specs[i]=np.expand_dims(S, -1)\n",
        "  print(specs.shape)\n",
        "  return specs\n",
        "\n",
        "#Waveform array from path of folder containing wav files\n",
        "def audio_array(path):\n",
        "  ls = glob(f'{path}/*.wav')\n",
        "  adata = []\n",
        "  filenames = []\n",
        "  for i in range(len(ls)):\n",
        "    try:\n",
        "      x, sr = tf.audio.decode_wav(tf.io.read_file(ls[i]), 1)\n",
        "      x = np.array(x, dtype=np.float32)\n",
        "      adata.append(x)\n",
        "      filenames.append(os.path.basename(ls[i]))\n",
        "    except (UnicodeDecodeError):\n",
        "      print('Unable to load:\\n' + ls[i])\n",
        "  return np.array(adata), filenames"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_spectrograms(dir_path, spectrograms, filenames, force_recreate=False):\n",
        "  if os.path.isdir(dir_path):\n",
        "    if not force_recreate:\n",
        "      print('Set ' + dir_path + ' already exists')\n",
        "      return\n",
        "    else:\n",
        "      shutil.rmtree(dir_path)\n",
        "\n",
        "  os.makedirs(dir_path)\n",
        "\n",
        "  class_name = os.path.dirname(dir_path)\n",
        "\n",
        "  for i in range(len(spectrograms)):\n",
        "    np.save(os.path.join(dir_path, filenames[i]), spectrograms[i])\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "-WJU8iGccbAd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_BASE_PATH = '/content/drive/MyDrive/GTZAN_dataset'\n",
        "WAV_DATASET_PATH = os.path.join(DATASET_BASE_PATH, 'genres_16khz')\n",
        "\n",
        "def generate_spectrograms_dataset(genre):\n",
        "  awv, filenames = audio_array(os.path.join(WAV_DATASET_PATH, genre))\n",
        "\n",
        "  aspec = to_melspec(awv)\n",
        "  save_spectrograms(os.path.join(DATASET_BASE_PATH, 'genres_melspectrograms', genre), aspec, filenames)\n",
        "\n",
        "  aspec = to_stftspec(awv)\n",
        "  save_spectrograms(os.path.join(DATASET_BASE_PATH, 'genres_stftspectrograms', genre), aspec, filenames)"
      ],
      "metadata": {
        "id": "D4BlcPnFoI3k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK_UnhfMELHD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81f6f879-5c0f-4edb-c50e-fb286b847817"
      },
      "source": [
        "genres = ['jazz', 'classical']\n",
        "\n",
        "for genre in genres:\n",
        "  generate_spectrograms_dataset(genre)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2530, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2501, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2517, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2515, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2523, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2521, 1)\n",
            "(192, 2541, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2530, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(192, 2502, 1)\n",
            "(99,)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n",
            "(577, 2502, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c6db12297db1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgenre\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mgenerate_spectrograms_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-e04075ed209c>\u001b[0m in \u001b[0;36mgenerate_spectrograms_dataset\u001b[0;34m(genre)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#save_spectrograms(os.path.join(DATASET_BASE_PATH, 'genres_melspectrograms', genre), aspec, filenames)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0maspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_stftspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mawv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;31m#save_spectrograms(os.path.join(DATASET_BASE_PATH, 'genres_stftspectrograms', genre), aspec, filenames)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e036e96ec92c>\u001b[0m in \u001b[0;36mto_stftspec\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstftprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-93aea4dc3a71>\u001b[0m in \u001b[0;36mstftprep\u001b[0;34m(wv, hop)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstftprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mref_level_db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[1;32m     81\u001b[0m         return F.spectrogram(waveform, self.pad, self.window, self.n_fft, self.hop_length,\n\u001b[0;32m---> 82\u001b[0;31m                              self.win_length, self.power, self.normalized)\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/functional.py\u001b[0m in \u001b[0;36mspectrogram\u001b[0;34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mspec_f\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpower\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mspec_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspec_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/functional.py\u001b[0m in \u001b[0;36mcomplex_norm\u001b[0;34m(complex_tensor, power)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpower\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "awv, filenames = audio_array(os.path.join(WAV_DATASET_PATH, 'jazz'))\n",
        "aspec = to_melspec(awv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwiPU6KnCAZH",
        "outputId": "a4efd6c2-671f-46c1-ee1b-2d9f60289cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unable to load:\n",
            "/content/drive/MyDrive/GTZAN_dataset/genres_original/jazz/jazz.00054.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aspec[0].shape"
      ],
      "metadata": {
        "id": "QhXWIsR5iPd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390fef12-ac9d-46b0-c29d-be141526a85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192, 3447, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}